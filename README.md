#llama_v2v

Voice to voice Llama3 responder with openai-whisper and MARS5-TTS as audio-to-text and text-to-audio models with RunPod serverless GPU computing via REST API.

In the end project looks good, but pushing to image to docker takes ages, computing on edge takes ages. It's boring. I'm abandoning the ship. If you'd like to test it, build the image and start with glue.doStuff in notebook.

Possible next chapter is transforming it from serverless REST API to wild notebook so it can run on free GPU on colab or kaggle :)))
